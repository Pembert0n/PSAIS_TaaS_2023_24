 Knowledge Science – der Podcast über künstliche Intelligenz im Allgemeinen und Natural-Language-Processing im Speziellen. Mittels KI-Wissen entdecken, aufbereiten und nutzbar machen. Das ist die Idee hinter Knowledge Science. Durch Entmüstifizierung der künstlichen Intelligenz und vielen praktischen Interviews machen wir dieses Thema wöchentlich greifbar. Willkommen zum Podcast von Sigurd Schacht und Karsten Lankion. Herzlich willkommen zu unser ersten Sendung des Podcast Knowledge Science. Die erste Sendung hat natürlich zum Ziel auch zu erklären, was wir denn mit dem Podcast erreichen wollen. Warum wir diesen Podcast machen wollen? Das möchten wir jetzt kurz darstellen. Das Ziel des Podcasts ist es, eine wöchentliche Diskussion zu dem Thema künstliche Intelligenz und Knowledge Science anzutreten, hier aufzuzeigen und darüber zu sprechen. Wir wollen dem Podcast mit Interviews aus der Industrie, Forschung und Lehre speziell zu dem Thema Anwendung in der KI und Knowledge Science anreichern und damit ein Einblick hinter die Kulissen bringen. Natürlich möchten wir auch aus unserer Hochschulerfahrung, in Vorstellungen von studentischen Forschungs- und Lehreprojekten hier aufzeigen. Dazu wollen wir aktuelle Themen State of the Art Berichte zu KI und Knowledge Science darstellen und damit insbesondere diese Themen endmüsifizieren und Transparenz schaffen. Nun, wer sind wir? Ich bin Karsten Lankion. Ich bin Professor für Business Intelligence und Data Science an der Hochschule Halbonen. Dort schon seit über das für vier Jahren in diesem Bereich tätig. Ich habe selbst Informatik studiert und bereits im Studium haben mich Vorlesungen zu zu neuronalen Netzen genetischen Algorithmen und Fasidlogik so fasziniert, dass ich mich seitdem mit diesen Themen beschäftige wie und was kann ich aus Daten lernen? Letztendlich der Kern des maschinellen Ernens, wie wir sehen werden, ein Teil der KI. Und ich bin Sigurd Schacht, Professor für angewandte künstliche Intelligenz und digitale Transformation an der Hochschule Ansbach. Vor der Professor war ich viele Jahre in der Wirtschaftsprüfung tätig und beschäftigte mich dort nahezu zwei Jahrzehnte lang mit den Themen rund um Daten, Analyse und der Ziel gerichtete Nutzung. Die Frage heute ist natürlich zunächst einmal, warum nennen wir den Podcast Knowledge Science? Was ist nun eigentlich Knowledge Science? Knowledge Science ist die automatisierte Identifikation, Extraction und Verknüpfung von Wissensfragmenten aus strukturierten und unstrukturierten Daten unter Verwendung der Methode der künstlichen Intelligenz. Ziel des Knowledge Science ist es eine vernetzte Wissensbasis für die automatisierte Wissenssicherung und Verarbeitung und Generation zu schaffen. Wo kann man das Ganze denn nun anwenden? Anwendung findet dies vor allem in Unternehmen zum Aufbau von Wissensmanagement und zu automatisierten Entscheidungsfindung. Kann aber natürlich auch genutzt werden, um ein persönliches Net-Bissensnetzwerk aufzubauen und das auch anwenden zu können. Jetzt haben wir die Definition Knowledge Science gehört und da kommen ja die Begriffe künstliche Intelligenz vor. In der heutigen Sendung möchten wir dementsprechend den Begriff künstlichen Intelligenz mal darstellen und wie Kastner schon gesagt hat, ein bisschen entmüsstifizieren. Was ist nun die künstliche Intelligenz? Es gibt viele verschiedene Definitionen zur künstlichen Intelligenz. Ich persönlich finde die Definition von Winsten ganz schön, der sagt künstliche Intelligenz ist die Untersuchung von Berechnungsverfahren, die es ermöglichen, wahrzunehmen, zur Schlussfolge und zu handeln. Somit wird versucht, dass menschliche Wahrnehmung und die menschliche Verstandesleistung zu operationalisieren. Wenn ich dich richtig verstehe, geht es darum, die menschliche Intelligenz jetzt endlich nachzubauen, dass man also das Thema Computer baut, die ein Verhalten an den Tag legen, die merkmale menschliche Intelligenz auch weil es stimmt ist. So würde ich das interpretieren. Es gibt unterschiedliche Definitionen an der Stelle, die natürlich auch in einer gewissen Weise in den Grad wie stark die künstliche Intelligenz auch wirklich in die Ligenz simulieren, oder tatsächlich abbildet. Da unterscheidet man dann zwischen starker KI, schwacher KI oder super Intelligenz. Aber was verstehmen denn unter schwacher KI? Na ja, der unter schwache KI brachte die KI eher als Simulation, als die Intelligenz. Es wird sozusagen eine Intelligenz simuliert und man greift hier vor allem auf die Methoden zurück, die aus der Mathematik, aus der Statistik, aus der Informatik kommt und der Fokus ist ganz stark auf ein einzelnes Problem gelegt. Oder siehst du es anders? Müssen wir vielleicht auch mal überlegen, was sind denn eigentlich typische menschliche Eigenschaften? Na, ich bin nicht darüber nachdenke, mir fällt ein Lernen, wie lernt man Sprache verstehen zum Beispiel. Diese Zinschlussfolger, allgemein vielleicht Probleme lösen. Wie löste mensch Probleme? Wie kann ich das abbilden auf einen Computer? Und diese Ziegerichte, diese kleinen abgeschotteten Probleme, die letztendlich automatisiert zu lösen, zu bearbeiten mit einem Computer. Mit der Perspektive ist doch das Meiste, was wir das lang sehen, eigentlich nur schwacher KI, oder? Sich genauso, sich genauso, weil ein wesentlicher Aspekt fehlt, die eigentlich die eigenständige Problemlösung, die man bei einer Stagen KI erwarten würde. Eine Stagel KI sieht es ganz so, dass sie nicht nur das ganze Thema, also die menschliche Verstandesleistung simuliert, sondern dass sie eigenständige Probleme löst und an eigenes ständiges Verhalten an den Tag liegt. Wenn wir mal zurückkommen zur Zürichsache KI, aber das ist ja das jetzt gerade dominant ist, denn ich denke mal, Stagel KI, da wird man vielleicht kommt, man da in einigen Jahrzehnten hin und ich glaube, das ist er der Teil, vor dem Menschen Angst haben. Wenn Computer eigenständig versuchen Dinge zu optimieren, zu lösen, aber da sind wir noch sehr weit von weg. Beschäftig und erst mal mit der schwachen KI. Es gibt so eine Aussage, ein Zitat, was mich sehr interessiert hat. Es bekannt als das Morabex Paradoxum, sagt halt, die schweren Dinge sind einfach und die einfachen Dinge sind schwer in der KI. Also, wir haben schon gesehen, es gibt KI Lösungen, die können Schach spielen. Die sind besser als der Weltbeste Schachspieler. Oder man muss noch weiter einfachen Optimierungsprobleme Sachen lösen, die Fritzagleichung lösen, nummerisch mal erbrechnen, können Computer unheimlich einfach. Aber so scheinbar, simpel Dinge, was das Gesicht der Mutter an einem Stapel von Bildern erkennen, laufen lernen, was Menschen, Babys, quasi ohne irgendwie Erklärung machen können, sowas nachzubauen ist schwer. Woran liegt denn das, Kassen? Ja, ich denke mal, dass das, muss halt überlegen, wie baut man jetzt eigentlich so eine KI? Was sind die Grundbestandteile? Man hat festgestellt, man immer ist viele gleichartige Berechnungen auf Basis von Daten gibt, die Computer gut durchführen können, indem man ein Problem einfach formalisieren kann. Also, ab wenn es viele Möglichkeiten gibt, die ihn rechnen durchprobieren können. Aber wenn sie gleichartig wohl definiert sind, dann kann der Computer seine Stärke ausspielen. Sobald es aber Kreativität erfordert, sobald es irgendwelche Datenerfahrungen aus dem Kontext benötigt, die vielleicht gar nicht formalisiert und erfasst sind, dann ist der Mensch gut dabei. Ich denke mal, die Prozesse wie Menschen wirklich lernen aus dem Nichtzerraus mit wenig Eingabe Daten, weiß nicht, ob die schon so ausgiebig erforscht sind, dass man das nachbauen kann. Man könnte das letztendlich interpretieren, dazu ein Reverse-Engineering, diese ganzen Prozesse des Lernens zu entschlüsseln, sehrlich ein Forschungsbereich der KI, diese Prozesse zu verstehen und nachzubauen. Bis lang, denke ich, geht es eher darum aus Daten, aus Erfahrungen, die man gesammelt und gespeichert hat, endlich erkenntnisse herauszuziehen. Und dann sind wir wieder bei einem Punkt, einem Teilbereich der KI, nämlich den Maschinen lernen, als ein wesentlichen Treiber, wie wir später noch sehen werden. Aber was gibt es noch 5 Standteile einer KI? Pferd bei der schwachen KI müssen wir ja sehen, dass wir einerseits die Datenverarbeitung haben, also was du gerade gesagt hast, Maschinenelles lernen. Aber es ist natürlich auch wichtig, wenn wir die menschliche Leistung simulieren wollen, dass wir Themen haben, dass wir zum Beispiel Schriften erkennen können, also Sprachen erkennen können, also gesprochenes Sprachen, geschriebenes Sprachen. Aber natürlich auch die Bildverarbeitung, das ist ein wichtiger Part der in der künstlichen Delerenz an wesentlichen Teil, also gerade auch in der schwachen künstlichen Delerenz in wesentlichen Teil ausmacht. Wenn wir jetzt hier in unserem Podcast gucken, das Thema Noted Science, dann ist natürlich auch ein wichtiger Part des sogenannten Noted Generation und Navigation, das wäre so sagen, dass wir auch aus den gegebenen Daten wissen, generieren Informationen herausziehen und die miteinander vernetzen. Und das Ganze natürlich auf Basis der Daten, die man verfügbar hat. Wir lernen ja in einer gewissen Weise aus historischen Informationen. Und ich glaube, das, was du gerade gesagt hast, warum ist der Menschen manchen Stellen besser? Man hört ja immer wieder die Diskussionen an der Stelle, dass der Mensch vor allem enorm stark ist. Wenn man eine schwache Datenlage hat, vielleicht auch eine ungewisse Datenlage und darauf dann Schätzungen oder Prognosen oder ähnliches abgegeben muss. Da ist der Mensch unheimlich stark. Aber bei großen Mengen, wo viele Muster oder einiges drin sind, da versagen wir dann als Menschen in der gewissen Weise, wo dann die Maschine tendenziell eher stärker ist. Und das sehen wir dann auch bei solchen Themen, wie du es schon erwähnt hast mit dem Thema Schach spielen oder wenn wir daran denken, was ja noch komplizierter als Schach ist, die Go, weil es wildmeisterchaften oder Go-Spiele, wo die Maschine auch aufgrund dieser Massendaten natürlich sehr gut berechnen kann, welche Züge oder welche Themen jetzt jetzt im nächsten Schritt im Vorteil haben. Wenn wir mal um die zurückblicken, mal überlegen, dass die künstlichen Intelligenen so als Forschungsgebiet geht, geht ja zurück auf die 50er Jahre, 1956, haben einige Bekannte Köpfe aus dem Umfeld zu einer Konferenz eingeladen, um das Gebiet der KI letztendlich abzustecken. Sie so bekannte Datenautskonferenz in Hannover und New Hampshire. Und schon mal ein Da-Kamer heraus, dass die Aufgaben der KI gar nicht einheitlich definiert und gesehen werden können, es gab viele Aspekte, die dort adressiert wurden. Und ich glaube, in der Anfangszeit war ein interessanter Zweig der KI, auch immer noch, dass ich wirklich eine Systembauer, das von einem Menschen auch gar nicht wirklich unterschied werden kann. Mir war es auch operiert von, natürlich auch selber, gelesen, aber das war ein weiß-mauen Experiment, mit dem Chat-Bott-Eleiser. Kannst du doch mal was erzählen, das sind eine sehr interessante Geschichte. Ja, das ist super spannend. Der Erweizenbaum ist ein Wissenschaftler gewesen, und hat 1966 einen Programm entwickelt, Elisa, das auf die Idee war, einer gewissen Weise, ein Kommunikationsprogramm zu entwickeln und damit Kommunikationen zwischen Menschen und Maschine zu etablieren. Und der spannende daran war, dass er eine gewissenweise auch in seinem Artikeln ein schönes Tidat genannt hat, denn in diesem Bereich, und damit meinte er die holistische Programmierung und die künstlichen Delegance, werden Maschinen dazu gebracht, sich ein wundersamen Weißen zu verhalten, häufig ausreichend gut, um selbst die erfahrensten Beobachter zu erstaunen. Und sein Programm, das war nicht der schöne, der hat im Endeffekt Dialoge genommen und mit Regeln hinterlegt, so dass in der gewissen Weise Antworten daraus kamen, die so aussahen, also simuliert, als ob die Maschine tatsächlich in ein Führungsvermögen hat und kommuniziert. Und das Ganze hat er dann auch ausprobiert im Bereich der Psychotarope-MP und hat dann Gespräche mit Psychotarapäuten mit der Maschine führen lassen. Und das war dann ganz spannend, weil dann natürlich so Fragen aufkamen. Mir geht es heute nicht so gut und daraufhin hat er die Maschine gefragt, oh das dreht mir aber. Wir können es einfach mal spielen. Hallo Siegut. Hallo. Wie geht's dir? Mir geht es heute leider nicht so gut an. Ich fühle mich einfach nicht. Das ist aber nicht schön, dass es dir nicht gut geht. Was ist denn da, wenn du da so eine Mäder rüber bist? Ja, ich habe irgendwie einen schlechten Tag heute und das liegt irgendwie an meine Einstellung. Als sie mir mehr bei deine Einstellungen? Ja, ich fühle mich irgendwie deprimiert und müde und raurig und ja, es macht dich denn deprimiert? Meine Arbeit, mein Umfeld, die Sorgen vor der nächsten Woche. Das tut mir leid. Was besorgt dich denn? Das ist ganz interessant, wie du diese Gesprächführung jetzt fürst war, genauso atgiert er auch die Maschine. Und ich glaub, der Zuhörer hat jetzt in der gewissen Weise mitgekriegt, dass da eigentlich klare Regeln dahinter sind. Also so, wenn ich eine Problem darstelle, wird nachgefragt, so dass man das wiederholen muss, teilweise werden Fragen einfach umgetreten und so weiter. Das spannende an dem Projekt war, dass damals die Psychotarapäuten wirklich Angst bekommen gesagt haben, wo kann ihr sein, dass so eine Maschine uns ersetzt? Wir werden ja völlig weg rationalisiert. Das ist ja hochprissant. Also, man hat im Endeffekt vor lauter Reaktion gar nicht hinter die Kulissen geguckt. Und dann hat er auch in seinem Artikel einen schönen, schönes 2-Destitat gebracht, was ich wirklich auch bezeichnet finde in dem Thema. Sobald das spezielle Programm jedoch demaskiert ist, also bei durch die regeln Darestät und erklärt sind, sobald seine inneren Mechanismen in einer verständigen Sprache erklärt sind, zerböckelt sein Sauber. Es ist enthüllt, als eine einfache Zusammenstellung von jeweils einfach nachvollziehbaren Prozituren. Und ich glaube, das macht es auch aus, wenn wir über künstliche Intelligenz-Religente Moment gerade, wenn man jetzt mit ihr Unternehmen redet, wenn man in der Wirtschaft schaut, wenn man sich ein bisschen umschaut, dann ist es ja wirklich so, dass fast überall, dass nicht eine Kixtoße in künstliche Intelligenz draufstehen hat, ist ja eigentlich schon fast ein wundermomentan, weil ja fast überall künstliche Intelligenz drin ist und man muss diese Stichwort unbedingt bringen. Aber es hat was mühstisches. So hat dem Motto, wir haben da künstliche Intelligenz drin und dann funktioniert alles. Und noch besser als vorher. Aber eigentlich ist bei der schwachen künstliche Intelligenz so, wie du es vorher auch dargestellt hast, überwiegend definierte Regeln, Abläufe dahinter, die Strukturen erkennen wollen, die Zusammenhänge erkennen und daraus dann in einer gewissen Weise prognosen in die Zukunft ableiten. Genau, und diese Regeln, die kann man natürlich manuell definieren. Nein, die ersten Versuche, Expertensysteme zum Beispiel aufzubauen, hat man ja tatsächlich versucht, solche Fakten zusammen zu tragen, Regeln zu definieren. Es hat sich aber ziemlich schnell gezeigt, dass das zwar generell funktionieren kann, aber im größeren Stil nicht blödlicherfolgreich ist. Es ist bekannt als sogenannte Knowledge Acquisition-Bottelnick. Also dieser Engpass, der sich dadurch ergibt, die die ganzen Fakten und Regeln zu kurdieren, manuell zu programmieren. Und aus dieser Notwendigkeit heraus hat sich der Zweig des Maschinenellen Nernzieher entwickelt. Das ist ja gesagt, ich habe zwar diese Regeln nicht, die zu programmieren, ist mühsam. Aber ich habe ja trotzdem sehr viel Daten, in denen sehr viel Erfahrung und Zusammenhänge drin stecken. Kann ich also diese Daten nicht nutzen, um aus denen automatisch die Regeln zu generieren und herauszuziehen. Das ist quasi die Geburtstunde des Maschinenellen Lernens. Und in dem Sinne ist das Maschinenelle Lernen ein Teilbereich der künstlichen Intelligenz. Und dieser Teilbereich hat sich inzwischen, würde ich sagen, versetzständig, gilt heute auch als eigenständige Disziplinen und findet in vielen Bereichen Anwendungen, die lange Zeit gar nicht unbedingt als KI abgestempelt wurden, vielleicht auch weil Menschen bedenken haben, wenn sie oder lange Zeit bedenken hatten, wenn sie künstliche Intelligenz hören, habe ich in eine Maschine, die denken, die führen kann und wie leicht man da aufs Glatt als geführt wird, zeigt ja dieses Experiment vom Weizenbaum. Denk mal Mensch, da ist ein Computer, Mensch, der hört wirklich zu, der hat Empathie. Dabei sind es nur ganz einfache Regeln, einfach mal nachfragen. Eine Frage umdrehen, die Maschine versteht nicht wirklich, was das Problem ist, aber man denkt es. Wenn man braucht man in dem Sinne gar keine Sorge zu haben, dass Algorithmen dieser Art jetzt um etwas Böses sind, sondern sie benden eigentlich nur Bekannte Sachen an, vom sie umbauen Regeln. Und dass dieser Zweige zu erfolgreich geworden ist in der Zeit, das ist ja interessant. Sie liegt sicherlich daran, wenn man mal guckt, es gibt immer mehr Daten, die zu Verfügung stehen, als hier mal Big Data ist bekannt. Wir haben immer mehr Daten, wir haben enorme Rechenleistungen und was fehlt noch, wie gut. Also, ich sehe das so, warum ist das so interessant und warum das jetzt gerade kommt, ist natürlich Datenrechenleistung, wie das genannt, das ist der erste Punkt. Aber du musst natürlich sehen, gerade in den Unternehmen haben wir den Aspekt, dass sehr battisch Entscheidungen getroffen werden. Du entscheidest dich ja für ein neues Produkt, für ein neuen Bereich, für die Einstellung von den Mitarbeiter oder den Aufbau von dem ganzen Werk oder Ähnliches. Und die Entscheidungen passieren aber in der Regel immer auf innergewissen Weise prognosen, prognosen, die du selber durchführst. Natürlich mit deinen Erfahrungen, aus deiner Berufserfahrung, 50 Jahre Erfahrung oder wie auch immer, oder aus dem Markt berubert. Wenn du weißt einfach, wenn das und das ist, hat dich bisher die Erfahrung gemacht, dass dann die und die Prognose getroffen werden muss oder dass das prognostiziert werden kann und ich daraufhin die, die die Entscheidungen treffen kann. Das interessante ist jetzt, wenn man das betrachtet, die künstliche Intelligenz oder das maschinelle Lernen macht ja eigentlich zumindest in einem Teilbereich, auch nichts anderes als prognosen. Wir nehmen im Endeffekt wissen aus den Daten, aus der Historie heraus und prognostizieren dann neue Daten setze, neue Datenpunkte, was damit gemeint ist oder in welche Kategorie die fallen oder ähnlich ist. Das heißt, was wir jetzt tun können, ist eigentlich diese beiden Welten miteinander zu verknüpfen, nämlich prognosen, die ich eigentlich im Unternehmen täglich machen muss, nämlich in meiner Kontrolle, in meinem Einkauf, in meinem Vertrieb oder ähnliches. Und die dann mit der künstlichen Intelligenz oder mit dem maschinellen Lernen zu untermauern. Und was dann der Effekt ist, ist, dass diese Informationsbeschaffung und die Prognosen dann wesentlich günstiger werden, weil sie ja maschinell durchgeführt werden können. Und nicht mehr durch eine menschens Leistung, die Informationen erst beschäftigen müssen, vielleicht Jahrzehntelange Erfahrungen da sein müssen oder ähnliches, sondern wir können einfach aus der historischen Datenlernen. Das heißt, wir schaffen es im Unternehmen prognosen, kosten günstiger zu erstellen, damit in vielen Bereichen überhaupt das Anwenden zu können, also in der Masse. Und damit bessere Entscheidungen hoffentlich, vielleicht auch nicht, aber hoffentlich zu treffen. Und das ist meiner Ansicht nach der große Effekt, warum es in den Unternehmen jetzt gerade so ein großer Hypes, weil wir einfach in den Fokus kommen, wir können kosten günstiger unsere Entscheidungen vorhanden. Ja, ich denke auch, dass das ein ganz zentraler Punkt ist, zumindest in Unternehmen, das ist ja auch einer unserer Hauptanwendungsbreiche der Fokusanwendung von KI in Unternehmen. Es gibt natürlich andere Bereiche, die nicht nur im Unternehmen sind, ganz sehr bekannt, so was wie es autonome Fahren zum Beispiel. Aber auch da kann man, wenn man das genauer aufschlüsselt, feststellen, ist basiert im Wesentlichen auf dem Erkennen von Kontext und der Treffen von Entscheidungen. Muss ich bremsen, wie schnell kann ich fahren, muss ich ausreichen. Man kann das zerlegt, wenn man feststellen, dass den Großteil der Teilaufgaben, die man in Anwendungsdomeen findet, darauf beruhen, dass die Entscheidung treffen muss. Und ich denke, wenn da nächsten Folge werden wir die Aufgaben, die in der typischen KI-Anwendungen stehen, mal genauer aufzuschüsseln, zu schauen, was gibt es dafür Probleme, was sind die Grundbausteine der KI, mit dem man so was lösen kann. Aber das hast du das ja schön eigentlich aufgegriffen, was in der nächsten Folge passieren wird. Wir würden natürlich gerne in dem Thema künstliche Intelligenz natürlich noch tiefe einsteigen und die einzelnen Aspekte, also praktisch Spracherkennung, Bilderkennung, maschinelles Lernen, auch nochmal detaillierter darstellen. Aber ich denke, für den heutigen ersten Podcast, das ist mein schöner Einblick gewesen, so ein schöner Tise, dass wir an der Stelle vielleicht auch ein bisschen in der Resse für mehr geschafft haben und würden uns natürlich freuen, wenn dann nächste Woche wieder etliche Personen zuhören würden, sodass wir das Thema so nach und nach immer tiefer aufgreifen können. Und wir dann natürlich auch die ersten in der Jupaten damit reinnehmen. Ja, da freue ich mich schon auf die nächste Woche. Das war eine weitere Folge des Knowledge Science Podcasts. Vergessen Sie nicht, nächste Woche wieder dabei zu sein. Vielen Dank fürs Zuhören. Copyright WDR 2020